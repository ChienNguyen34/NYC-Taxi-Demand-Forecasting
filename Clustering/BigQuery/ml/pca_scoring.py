# pca_scoring.py
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA


def compute_pca_demand_score(
    df: pd.DataFrame,
    output_table: str,
    client,
) -> pd.DataFrame:
    """
    Nh·∫≠n dataframe ƒë√£ s·∫°ch (kh√¥ng NaN), t√≠nh demand_score b·∫±ng PCA
    v√† ghi k·∫øt qu·∫£ v√†o BigQuery.
    """

    # 4 thu·ªôc t√≠nh d√πng ƒë·ªÉ h·ªçc tr·ªçng s·ªë
    feature_cols = [
        "total_trips",
        "avg_hourly_demand",
        "trips_per_km2",
        "weekend_ratio",
    ]

    # Ch·ªâ l·∫•y c√°c c·ªôt c·∫ßn thi·∫øt, v√† dropna 1 l·∫ßn n·ªØa cho ch·∫Øc
    df = df.dropna(subset=feature_cols).copy()

    X = df[feature_cols].values

    # Standardize
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # PCA 1 component
    pca = PCA(n_components=1)
    pca.fit(X_scaled)

    raw_weights = pca.components_[0]

    print("\nüîé PCA Loadings (raw):")
    for f, w in zip(feature_cols, raw_weights):
        print(f"{f:17s} -> {w:.4f}")

    abs_weights = np.abs(raw_weights)
    normalized_weights = abs_weights / abs_weights.sum()

    print("\nüìä PCA Contribution (%):")
    for f, w in zip(feature_cols, normalized_weights):
        print(f"{f:17s} -> {w*100:.2f}%")

    # ƒêi·ªÉm PC1
    pc1_scores = pca.transform(X_scaled)[:, 0]

    # N·∫øu ngh·ªãch d·∫•u v·ªõi total_trips th√¨ ƒë·∫£o
    corr = np.corrcoef(pc1_scores, df["total_trips"])[0, 1]
    if corr < 0:
        pc1_scores = -pc1_scores

    # Chu·∫©n ho√° 0‚Äì100
    pc1_min, pc1_max = pc1_scores.min(), pc1_scores.max()
    demand_score = 100 * (pc1_scores - pc1_min) / (pc1_max - pc1_min)
    df["demand_score"] = demand_score

    # B·∫£ng k·∫øt qu·∫£
    result = (
        df[
            [
                "zone_id",
                "pickup_zone_name",
                "demand_score",
                "total_trips",
                "avg_hourly_demand",
                "trips_per_km2",
                "weekend_ratio",
            ]
        ]
        .sort_values("demand_score", ascending=False)
        .reset_index(drop=True)
    )
    result.insert(0, "rank", result.index + 1)

    print("\nüèÜ Top 5 zone:")
    print(result.head())

    # Ghi BigQuery
    from google.cloud import bigquery
    job_config = bigquery.LoadJobConfig(write_disposition="WRITE_TRUNCATE")
    job = client.load_table_from_dataframe(result, output_table, job_config=job_config)
    job.result()
    print(f"\n‚úÖ ƒê√£ ghi k·∫øt qu·∫£ PCA v√†o b·∫£ng: {output_table}")

    return result
